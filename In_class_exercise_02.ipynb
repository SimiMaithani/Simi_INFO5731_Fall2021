{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimiMaithani/Simi_INFO5731_Fall2021/blob/main/In_class_exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAYj6GkTuw3O"
      },
      "source": [
        "## The third In-class-exercise (9/15/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4n45C6Nuw3S"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNMNoIXsuw3U"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTcUEOBtuw3V"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "My research question would be: Why and how have the occurances of natural disasters increased in the past 30 years?\n",
        "The dataset should include information about all the dates when natural disasters occured in the past. It should include the country/state/area where the natural \n",
        "disaster occured. Information about the type of terrain where the natural disaster occured is also important so that a relationship \n",
        "between the type of ground and the occurance of a natural disaster can be established. The dataset will also contain weather information at the time the natural\n",
        "disasters occured. \n",
        "The data will be collected from websites such as 'Socioeconomic Data and Applications Center' which contains huge information on natural disasters and \n",
        "save geocodes in their datasets that increase the accuracy of the outcome. Kaggle can also be used to gather information.\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJdH1Sjwuw3X"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 reviews of a movie from IMDB (https://www.imdb.com/) or 1000 reviews of a product from Amazon (https://www.amazon.com/).\n",
        "\n",
        "As for the IMDB movie review, the following informtion need to be collected (for example: https://www.imdb.com/title/tt6751668/reviews?ref_=tt_urv):\n",
        "\n",
        "(1) User name\n",
        "\n",
        "(2) Star\n",
        "\n",
        "(3) Review title\n",
        "\n",
        "(4) Review text\n",
        "\n",
        "(5) Review posted time\n",
        "\n",
        "\n",
        "As for the Amazon product review, the following information need to be collected (for example: https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=sr_1_3?crid=2E3C55VKJX0K3&dchild=1&keywords=machine+learning+andrew+ng&qid=1631718619&sr=8-3):\n",
        "\n",
        "(1) User name\n",
        "\n",
        "(2) Star\n",
        "\n",
        "(3) Review title\n",
        "\n",
        "(4) Review text\n",
        "\n",
        "(5) Review posted time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrlPFt24uw3Z",
        "outputId": "cc5e8920-2b59-492f-8d7f-774d80209ac4"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# Installing the necessary packages\n",
        "!pip install beautifulsoup4\n",
        "!pip install requests"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxL8jjGnRz7V"
      },
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "# importing the library used to query a website\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "#Specifying the url \n",
        "url = \"https://www.imdb.com/title/tt6751668/reviews?ref_=tt_urv\"\n",
        "#Query the website and return the html to the variable 'page'\n",
        "page = urllib.request.urlopen(url)\n",
        "#Parse the html in the 'page' variable and store it in Beautiful Soup\n",
        "soup = BeautifulSoup(page)\n",
        "# print(soup)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "l7GBPI-ks767",
        "outputId": "6a89be4f-c722-4893-8199-77e2de26ab06"
      },
      "source": [
        "# finding the user name from the html code using the .findall() method\n",
        "user_name = []\n",
        "for user in soup.find_all(\"span\",{'class':'display-name-link'}, 'a'):\n",
        "  user = user_name.append(user.text.strip())\n",
        "\n",
        "star = []\n",
        "for star_1 in soup.find_all(\"span\",{'class':'rating-other-user-rating'},'span'):\n",
        "  star_1 = star.append(star_1.text.strip())\n",
        "\n",
        "review_title = []\n",
        "for review_title_1 in soup.find_all(\"a\",{'class':'title'}):\n",
        "  review_title_1 = review_title.append(review_title_1.text.strip())\n",
        "\n",
        "review_text = []\n",
        "for review_text_1 in soup.find_all(\"div\", {'class':'text show-more__control'}):\n",
        "  review_text_1 = review_text.append(review_text_1.text.strip())\n",
        "\n",
        "review_posted_time = []\n",
        "for review_posted_time_1 in soup.find_all(\"span\",{'class':'review-date'}):\n",
        "  review_posted_time_1 = review_posted_time.append(review_posted_time_1.text.strip())\n",
        "\n",
        "number_of_reviews = 1000\n",
        "\n",
        "rev = {'User Name':user_name, \n",
        "       'Star':star,\n",
        "       'Review title':review_title, \n",
        "       'Review text':review_text, \n",
        "       'Review Posted Time':review_posted_time}\n",
        "  \n",
        "imdb_reviews = pd.DataFrame.from_dict(rev, orient='index')\n",
        "imdb_reviews.transpose()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User Name</th>\n",
              "      <th>Star</th>\n",
              "      <th>Review title</th>\n",
              "      <th>Review text</th>\n",
              "      <th>Review Posted Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mysticfall</td>\n",
              "      <td>10/10</td>\n",
              "      <td>For those who didn't like the movie because of...</td>\n",
              "      <td>It's not really a review but my attempt to exp...</td>\n",
              "      <td>18 October 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jeremy_Urquhart</td>\n",
              "      <td>10/10</td>\n",
              "      <td>One of the best films of this decade</td>\n",
              "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
              "      <td>5 July 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jtindahouse</td>\n",
              "      <td>8/10</td>\n",
              "      <td>You name a genre, this movie covers it</td>\n",
              "      <td>I can't remember the last time I saw a movie t...</td>\n",
              "      <td>6 October 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nehpetstephen</td>\n",
              "      <td>10/10</td>\n",
              "      <td>Meritocracy: it's metaphorical</td>\n",
              "      <td>In a meritocracy, success and fortune are rese...</td>\n",
              "      <td>25 August 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>keezo9uno</td>\n",
              "      <td>10/10</td>\n",
              "      <td>A true masterpiece.</td>\n",
              "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
              "      <td>19 August 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>impeyrules-54634</td>\n",
              "      <td>8/10</td>\n",
              "      <td>An original dark comedy about class struggles</td>\n",
              "      <td>This is a well written and well perfomed origi...</td>\n",
              "      <td>12 January 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MR_Heraclius</td>\n",
              "      <td>10/10</td>\n",
              "      <td>Great</td>\n",
              "      <td>The most original film of 2019 and it is wicke...</td>\n",
              "      <td>4 February 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sandeepventrapragada98</td>\n",
              "      <td>10/10</td>\n",
              "      <td>A brilliant piece of art which will slowly gro...</td>\n",
              "      <td>Well written and performed also technically sh...</td>\n",
              "      <td>19 August 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>DJKwa</td>\n",
              "      <td>9/10</td>\n",
              "      <td>Achieves what Jordan Peele set out to do with Us</td>\n",
              "      <td>As a film about a family imposing on another, ...</td>\n",
              "      <td>2 July 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tmcapitals</td>\n",
              "      <td>10/10</td>\n",
              "      <td>One of the most thought provoking films I've e...</td>\n",
              "      <td>Do you want to see a movie that will have your...</td>\n",
              "      <td>5 November 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>southbankcinema</td>\n",
              "      <td>10/10</td>\n",
              "      <td>Society can only be as strong as its most vuln...</td>\n",
              "      <td>Parasite (Gisaengchung), the 2019 film by Bong...</td>\n",
              "      <td>26 May 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>jmholmes-73727</td>\n",
              "      <td>9/10</td>\n",
              "      <td>FUNNY, TURNS SUDDENLY TWISTED, THEN SAD</td>\n",
              "      <td>This movie is so masterfully written and prese...</td>\n",
              "      <td>4 November 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>joesiegel</td>\n",
              "      <td>9/10</td>\n",
              "      <td>It's so metaphorical</td>\n",
              "      <td>\"It's so metaphorical\" is what Kevin says when...</td>\n",
              "      <td>30 January 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>dougal79</td>\n",
              "      <td>8/10</td>\n",
              "      <td>Whose the parasite and whose the cow?!</td>\n",
              "      <td>What an amazing film! Clearly an essay on the ...</td>\n",
              "      <td>17 August 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CineMuseFilms</td>\n",
              "      <td>9/10</td>\n",
              "      <td>A black comedy on social inequality</td>\n",
              "      <td>There is no shortage of films that depict the ...</td>\n",
              "      <td>28 December 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>perica-43151</td>\n",
              "      <td>6/10</td>\n",
              "      <td>Multilayered portrayal of the real Korea</td>\n",
              "      <td>This is a movie about a class struggle in Sout...</td>\n",
              "      <td>16 January 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>matthew-41243</td>\n",
              "      <td>7/10</td>\n",
              "      <td>Ok film, but that's all. Overrated for sure.</td>\n",
              "      <td>The film is ok but that's as far as I go. It's...</td>\n",
              "      <td>7 January 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>howard.schumann</td>\n",
              "      <td>6/10</td>\n",
              "      <td>Lacks any realistic human dimension</td>\n",
              "      <td>South Korean director Bong Joon-ho (\"Okja\") sa...</td>\n",
              "      <td>15 October 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>bp29</td>\n",
              "      <td>5/10</td>\n",
              "      <td>My God People, Really?? Get Your heads out of ...</td>\n",
              "      <td>After reading all the glowing reviews, especia...</td>\n",
              "      <td>8 February 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>vickythomson</td>\n",
              "      <td>10/10</td>\n",
              "      <td>Overhyped, not that interesting and long</td>\n",
              "      <td>I'm sorry but I must be living on another plan...</td>\n",
              "      <td>18 February 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>novacasa42</td>\n",
              "      <td>8/10</td>\n",
              "      <td>A Masterpiece/Work of Art.</td>\n",
              "      <td>As I write this, I want to describe my raw ini...</td>\n",
              "      <td>26 November 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>iamianiman</td>\n",
              "      <td>5/10</td>\n",
              "      <td>A cordial invitation to welcome this Parasite ...</td>\n",
              "      <td>Following the step of Get Out, it is a powerfu...</td>\n",
              "      <td>9 August 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>aguilar-85009</td>\n",
              "      <td>None</td>\n",
              "      <td>Not that deep, severely overrated</td>\n",
              "      <td>There are a few suspenseful scenes and a decen...</td>\n",
              "      <td>27 February 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>federovsky</td>\n",
              "      <td>None</td>\n",
              "      <td>Objectionable</td>\n",
              "      <td>How has this film has won the best film Oscar?...</td>\n",
              "      <td>10 February 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 User Name  ... Review Posted Time\n",
              "0               mysticfall  ...    18 October 2019\n",
              "1          Jeremy_Urquhart  ...        5 July 2019\n",
              "2              jtindahouse  ...     6 October 2019\n",
              "3            nehpetstephen  ...     25 August 2019\n",
              "4                keezo9uno  ...     19 August 2019\n",
              "5         impeyrules-54634  ...    12 January 2020\n",
              "6             MR_Heraclius  ...    4 February 2020\n",
              "7   sandeepventrapragada98  ...     19 August 2019\n",
              "8                    DJKwa  ...        2 July 2019\n",
              "9               tmcapitals  ...    5 November 2019\n",
              "10         southbankcinema  ...        26 May 2019\n",
              "11          jmholmes-73727  ...    4 November 2019\n",
              "12               joesiegel  ...    30 January 2020\n",
              "13                dougal79  ...     17 August 2019\n",
              "14           CineMuseFilms  ...   28 December 2019\n",
              "15            perica-43151  ...    16 January 2020\n",
              "16           matthew-41243  ...     7 January 2020\n",
              "17         howard.schumann  ...    15 October 2019\n",
              "18                    bp29  ...    8 February 2020\n",
              "19            vickythomson  ...   18 February 2020\n",
              "20              novacasa42  ...   26 November 2019\n",
              "21              iamianiman  ...      9 August 2019\n",
              "22           aguilar-85009  ...   27 February 2020\n",
              "23              federovsky  ...   10 February 2020\n",
              "\n",
              "[24 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASi2YQfhuw3a"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/). \n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZTs0NfDuw3b"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "#importing libraries\n",
        "import pandas as pd\n",
        "# importing the library used to query a website\n",
        "import urllib.request\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "#Specifying the url \n",
        "scholar = \"https://citeseerx.ist.psu.edu/search?q=computer&submit.x=0&submit.y=0&sort=rlv&t=doc\"\n",
        "#Query the website and return the html to the variable 'page'\n",
        "page1 = urllib.request.urlopen(scholar)\n",
        "#Parse the html in the 'page' variable and store it in Beautiful Soup\n",
        "soup1 = BeautifulSoup(page1)\n",
        "\n",
        "#print(soup1)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "sZlHYxUYGKtQ",
        "outputId": "1f48e10f-aba8-491d-929d-415f5cebcbc7"
      },
      "source": [
        "# finding the correct html code using the .findall() method\n",
        "title = []\n",
        "for ti in soup1.find_all('a',{'class':'remove doc_details'}):\n",
        "  ti = title.append(ti.text.strip())\n",
        "\n",
        "year = []\n",
        "for ye in soup1.find_all(\"span\",{'class':'pubyear'}):\n",
        "  ye = year.append(ye.text.strip())\n",
        "\n",
        "authors = []\n",
        "for au in soup1.find_all('span',{'class':'authors'}):\n",
        "  au = authors.append(au.text.strip())\n",
        "\n",
        "abstract = []\n",
        "for abstra in soup1.find_all(\"div\",{'class': 'snippet'}):\n",
        "  abstra = abstract.append(abstra.text.strip())\n",
        "\n",
        "# creating a dictionary for saving the values from the above lists in it\n",
        "articles = {'Title':title ,  \n",
        "            'Year':year, \n",
        "            'Authors':authors, \n",
        "            'Abstract':abstract}\n",
        "            \n",
        "# A dataframe for the desired output\n",
        "articles_frame = pd.DataFrame.from_dict(articles, orient='index')\n",
        "articles_frame.transpose()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Maximum likelihood from incomplete data via th...</td>\n",
              "      <td>, 1977</td>\n",
              "      <td>by \\n                  A. P. Dempster, N. M. L...</td>\n",
              "      <td>\"... A broadly applicable algorithm for comput...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Affective Computing</td>\n",
              "      <td>, 1995</td>\n",
              "      <td>by \\n                  R. W. Picard</td>\n",
              "      <td>\"... Recent neurological studies indicate that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Evolutionary Computing</td>\n",
              "      <td>, 2005</td>\n",
              "      <td>by \\n                  A. E. Eiben , M. Schoen...</td>\n",
              "      <td>\"... Evolutionary computing (EC) is an excitin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Computer Vision</td>\n",
              "      <td>, 1982</td>\n",
              "      <td>by \\n                  Kusuma Kumari B. M</td>\n",
              "      <td>\"... Driver inattention is one of the main cau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Computational Geometry</td>\n",
              "      <td>, 1978</td>\n",
              "      <td>by \\n                  Michael Ian Shamos</td>\n",
              "      <td>\"...   ...\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A View Of Cloud Computing</td>\n",
              "      <td>, 2010</td>\n",
              "      <td>by \\n                  Michael Armbrust , Arma...</td>\n",
              "      <td>\"...  Clearing the clouds away from the true p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Location Systems for Ubiquitous Computing</td>\n",
              "      <td>, 2001</td>\n",
              "      <td>by \\n                  Jeffrey Hightower,  Gae...</td>\n",
              "      <td>\"... This survey and taxonomy of location syst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Pervasive Computing: Vision and Challenges</td>\n",
              "      <td>, 2001</td>\n",
              "      <td>by \\n                  M. Satyanarayanan</td>\n",
              "      <td>\"... This paper discusses the challenges in co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Context-Aware Computing Applications</td>\n",
              "      <td>, 1995</td>\n",
              "      <td>by \\n                  Bill Schilit, Norman Ad...</td>\n",
              "      <td>\"... This paper describes systems that examine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>An axiomatic basis for computer programming</td>\n",
              "      <td>, 1969</td>\n",
              "      <td>by \\n                  C. A. R. Hoare</td>\n",
              "      <td>\"... In this paper an attempt is made to explo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                           Abstract\n",
              "0  Maximum likelihood from incomplete data via th...  ...  \"... A broadly applicable algorithm for comput...\n",
              "1                                Affective Computing  ...  \"... Recent neurological studies indicate that...\n",
              "2                             Evolutionary Computing  ...  \"... Evolutionary computing (EC) is an excitin...\n",
              "3                                    Computer Vision  ...  \"... Driver inattention is one of the main cau...\n",
              "4                             Computational Geometry  ...                                        \"...   ...\"\n",
              "5                          A View Of Cloud Computing  ...  \"...  Clearing the clouds away from the true p...\n",
              "6          Location Systems for Ubiquitous Computing  ...  \"... This survey and taxonomy of location syst...\n",
              "7         Pervasive Computing: Vision and Challenges  ...  \"... This paper discusses the challenges in co...\n",
              "8               Context-Aware Computing Applications  ...  \"... This paper describes systems that examine...\n",
              "9        An axiomatic basis for computer programming  ...  \"... In this paper an attempt is made to explo...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFRN8W8_uw3d"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEUqBTHvuw3e"
      },
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}